{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "UjxDgzbHAIMx",
        "outputId": "932e9c11-0470-4d85-bba8-90a89f35f4ed"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pandas'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Dropout, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import tensorflow.lite as tflite\n",
        "\n",
        "# Define correct column names based on UNSW-NB15 dataset\n",
        "column_names = [\n",
        "    \"srcip\", \"sport\", \"dstip\", \"dsport\", \"proto\", \"state\", \"dur\", \"sbytes\", \"dbytes\",\n",
        "    \"sttl\", \"dttl\", \"sloss\", \"dloss\", \"service\", \"Sload\", \"Dload\", \"Spkts\", \"Dpkts\",\n",
        "    \"swin\", \"dwin\", \"stcpb\", \"dtcpb\", \"smeansz\", \"dmeansz\", \"trans_depth\", \"res_bdy_len\",\n",
        "    \"Sjit\", \"Djit\", \"Stime\", \"Ltime\", \"Sintpkt\", \"Dintpkt\", \"tcprtt\", \"synack\", \"ackdat\",\n",
        "    \"is_sm_ips_ports\", \"ct_state_ttl\", \"ct_flw_http_mthd\", \"is_ftp_login\", \"ct_ftp_cmd\",\n",
        "    \"ct_srv_src\", \"ct_srv_dst\", \"ct_dst_ltm\", \"ct_src_dport_ltm\", \"ct_dst_sport_ltm\",\n",
        "    \"ct_dst_src_ltm\", \"attack_cat\", \"label\"\n",
        "]\n",
        "\n",
        "# Load and merge dataset with correct column names\n",
        "files = ['UNSW-NB15_1.csv', 'UNSW-NB15_2.csv', 'UNSW-NB15_3.csv', 'UNSW-NB15_4.csv']\n",
        "df = pd.concat([pd.read_csv(file, names=column_names, skiprows=1) for file in files], ignore_index=True)\n",
        "\n",
        "# Display column names to verify\n",
        "print(\"✅ Columns have been correctly renamed:\", df.columns)\n",
        "print(df.head())  # Show first 5 rows to confirm it's correct\n",
        "\n",
        "# Handle missing values\n",
        "df.fillna(0, inplace=True)  # Replace NaNs with 0\n",
        "\n",
        "df[\"attack_cat\"] = df[\"attack_cat\"].fillna(\"Unknown\")\n",
        "\n",
        "# Identify the correct target column\n",
        "if \"label\" in df.columns:\n",
        "    target_column = \"label\"\n",
        "    print(\"✅ Using 'label' for binary classification.\")\n",
        "elif \"attack_cat\" in df.columns:\n",
        "    target_column = \"attack_cat\"\n",
        "    print(\"✅ Using 'attack_cat' for multi-class classification.\")\n",
        "else:\n",
        "    print(\"❌ Error: No valid target column found in dataset.\")\n",
        "    exit()\n",
        "\n",
        "# Convert categorical columns to numeric\n",
        "label_encoder = LabelEncoder()\n",
        "for column in df.select_dtypes(include=['object']).columns:\n",
        "    df[column] = label_encoder.fit_transform(df[column].astype(str))\n",
        "\n",
        "# Define features and target\n",
        "X = df.drop(columns=[target_column, \"attack_cat\"], errors='ignore')\n",
        "y = df[target_column].astype(int)  # Ensure y is an integer\n",
        "\n",
        "# Normalize data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Compute class weights to handle imbalance\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
        "\n",
        "# Build deep learning model\n",
        "model = Sequential([\n",
        "    Dense(128, input_shape=(X_train.shape[1],)),\n",
        "    LeakyReLU(alpha=0.1),  # Prevents dead neurons\n",
        "    Dropout(0.5),\n",
        "    Dense(64),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    Dropout(0.3),\n",
        "    Dense(32),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    Dense(1, activation='sigmoid') if target_column == \"label\" else Dense(len(np.unique(y)), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile model with lower learning rate\n",
        "optimizer = Adam(learning_rate=0.00005)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='binary_crossentropy' if target_column == 'label' else 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model with early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=128, validation_data=(X_test, y_test), class_weight=class_weight_dict, callbacks=[early_stop])\n",
        "\n",
        "# Evaluate model\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(int) if target_column == 'label' else model.predict(X_test).argmax(axis=1)\n",
        "print(f'Accuracy: {accuracy_score(y_test, y_pred):.4f}')\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Save model\n",
        "model.save(\"IDS_UNSW15_Model.h5\")\n",
        "\n",
        "# Convert model to TensorFlow Lite format\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TFLite model\n",
        "with open(\"IDS_UNSW15_Model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"✅ Model converted and saved as TensorFlow Lite format!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "SbYJGP0lCDQe",
        "outputId": "d6a1a390-5ac7-491c-9e10-50fdcbe68ecc"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'column_names' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8fed874afe95>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"UNSW-NB15_1.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Fill missing values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'column_names' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the dataset\n",
        "df_test = pd.read_csv(\"UNSW-NB15_1.csv\", names=column_names, skiprows=1)\n",
        "\n",
        "# Fill missing values\n",
        "df_test.fillna(0, inplace=True)\n",
        "\n",
        "# Extract features and normalize\n",
        "X_test_sample = df_test.drop(columns=[\"label\", \"attack_cat\"], errors=\"ignore\")\n",
        "scaler = StandardScaler()\n",
        "X_test_sample_scaled = scaler.fit_transform(X_test_sample)\n",
        "\n",
        "# Load the TFLite model\n",
        "interpreter = tf.lite.Interpreter(model_path=\"IDS_UNSW15_Model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input/output details\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Run predictions on a sample batch\n",
        "num_samples = 500  # Adjust for presentation\n",
        "normal_count, attack_count = 0, 0\n",
        "\n",
        "for i in range(num_samples):\n",
        "    sample = np.expand_dims(X_test_sample_scaled[i], axis=0).astype(np.float32)\n",
        "\n",
        "    # Set input tensor\n",
        "    interpreter.set_tensor(input_details[0]['index'], sample)\n",
        "\n",
        "    # Run inference\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Get output tensor\n",
        "    prediction = interpreter.get_tensor(output_details[0]['index'])[0]\n",
        "\n",
        "    # Binary classification: 0 = Normal, 1 = Attack\n",
        "    if prediction > 0.5:\n",
        "        attack_count += 1\n",
        "    else:\n",
        "        normal_count += 1\n",
        "\n",
        "# Create a visualization\n",
        "labels = [\"Normal Traffic\", \"Malicious Traffic\"]\n",
        "counts = [normal_count, attack_count]\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(labels, counts, color=[\"green\", \"red\"])\n",
        "plt.title(\"Model Detection: Normal vs Malicious Traffic\")\n",
        "plt.xlabel(\"Traffic Type\")\n",
        "plt.ylabel(\"Number of Predictions\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
